{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usvenkat/AI-Agent_Developer-2/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5zUa8xY9xYc",
        "outputId": "b4346daa-1aea-41a4-bfa1-c6524a201528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yJMkECH5KmxI"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cpud8LWiK0CQ",
        "outputId": "d41f0c1b-07c9-4d8d-b713-1161a8f2ff8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "a = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "eB1E7fjRK_B5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c447c90-007e-44af-8f39-4943647b5c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: the product is good\n",
            "[{'label': 'POSITIVE', 'score': 0.9998664855957031}]\n"
          ]
        }
      ],
      "source": [
        "text = input(\"Enter the text: \")\n",
        "print(a(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "MmlPbrqtLeEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07d0c00-27c3-46b7-ef98-d578035e540f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: not a good quality\n",
            "[{'label': 'NEGATIVE', 'score': 0.9997479319572449}]\n"
          ]
        }
      ],
      "source": [
        "text = input(\"Enter the text: \")\n",
        "print(a(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "yWaU06lNNtjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c6d72f-ee57-46f9-8a4d-df763dbdf7ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "gen = pipeline('text-generation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSyvQiKSOkOh",
        "outputId": "b73d1cae-79f5-4121-9393-420d7308b2f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the text: one piece\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "text = input(\"Enter the text: \")\n",
        "t = (gen(text,max_length = 200))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nO4xc8AuPA9Y",
        "outputId": "54dfd995-63ca-4615-bbae-60e10e36cc62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hi would know by now why he had been able to become president of the United States and why he was so pleased to have been brought into this position and with so many great friends, both in Congress and in government, to hold the office in which I was elected for ten years: The other people, with considerable confidence and credit, of which I had no doubt that they would believe this, were more than willing to send in so many of their own for the appointment, and, with this, they knew it would not be too bad to lose it. It is too late to change that fact now. I know that if ever men like President James Polk were appointed for the Presidency, every one would be prepared to resign for that purpose. I wish that if he had been in this position when I was fifteen, he would have been more ready to give full consideration to what could do the honor and reputation of a Presidency and to have such powerful and influential friends as he had. It will not\n"
          ]
        }
      ],
      "source": [
        "print(t[0].get('generated_text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDuycIRmcVoc",
        "outputId": "5354dd36-edf5-4698-ae04-5339666de61a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "nameEntity = pipeline('ner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L008dEHyPvmT",
        "outputId": "22f69c78-3c4a-4912-e0c9-0ea3134d787d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "textNew = input(\"Enter the text: \")\n",
        "res = nameEntity(textNew)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fW8C47PeNym",
        "outputId": "2764c22f-5321-48f3-8055-6de83d48e4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "qp= pipeline('question-answering')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "2ujronk2bHHd"
      },
      "outputs": [],
      "source": [
        "c = '''In our college there are conducting. training sections for hole b tech department . in this training sections each section has their owne faculty our faculty name is kalki'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "od2xImA6d6wB"
      },
      "outputs": [],
      "source": [
        "q = \"what is our faculty name?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rbZyc8ceDxk",
        "outputId": "55198db0-8056-434e-92ee-6eeae27ea74d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9874528050422668, 'start': 166, 'end': 171, 'answer': 'kalki'}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "qp(question = q, context = c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTymhmxueVB_",
        "outputId": "df6ad43a-8b4b-4a9d-f53c-312a137a1811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "ts = pipeline('summarization')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "hS5PoNadhLfl"
      },
      "outputs": [],
      "source": [
        "text =''' Kaggle is a data science competition platform and online community for data scientists and machine learning practitioners under Google LLC. Kaggle enables users to find and publish datasets, explore and build models in a web-based data science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.[1]\n",
        "\n",
        "History\n",
        "Kaggle was founded by Anthony Goldbloom in April 2010.[2] Jeremy Howard, one of the first Kaggle users, joined in November 2010 and served as the President and Chief Scientist.[3] Also on the team was Nicholas Gruen serving as the founding chair.[4] In 2011, the company raised $12.5 million and Max Levchin became the chairman.[5] On March 8, 2017, Fei-Fei Li, Chief Scientist at Google, announced that Google was acquiring Kaggle.[6]'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsuyccR2hXeW",
        "outputId": "997573d7-97c6-47c4-90c0-765a0b111b06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Kaggle is a data science competition platform and online community for data scientists and machine learning practitioners under Google LLC . Users can find and publish datasets, explore and build models in a web-based data science environment, work with other data scientists, and enter competitions to solve data science challenges . On March 8, 2017, Fei-Fei Li, Chief Scientist at Google, announced that Google was acquiring\\xa0Kaggle .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "ts(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eQsVYKBhaNo",
        "outputId": "4073c809-338d-4d5d-8ce1-4b5730a41342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "u = pipeline('fill-mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xtMMj0NhoxE",
        "outputId": "db5db9f9-94d4-4208-a0a3-3746e7fe73a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.333689421415329,\n",
              "  'token': 15,\n",
              "  'token_str': ' on',\n",
              "  'sequence': \"i'm teacher on the board\"},\n",
              " {'score': 0.16045643389225006,\n",
              "  'token': 420,\n",
              "  'token_str': ' across',\n",
              "  'sequence': \"i'm teacher across the board\"},\n",
              " {'score': 0.10459846258163452,\n",
              "  'token': 9,\n",
              "  'token_str': ' of',\n",
              "  'sequence': \"i'm teacher of the board\"},\n",
              " {'score': 0.08620543777942657,\n",
              "  'token': 23,\n",
              "  'token_str': ' at',\n",
              "  'sequence': \"i'm teacher at the board\"},\n",
              " {'score': 0.0643916055560112,\n",
              "  'token': 13,\n",
              "  'token_str': ' for',\n",
              "  'sequence': \"i'm teacher for the board\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "result = u(\"i'm teacher <mask> the board\")\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "7wgRlnhQioJI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNd4O5uR32OZ4mFdtGSb6AO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}